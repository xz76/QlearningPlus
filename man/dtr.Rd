% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dtr.R
\name{dtr}
\alias{dtr}
\title{Dynamic Treatment Regime Estimation via Q-learning and Extensions}
\usage{
dtr(
  data,
  formula = f1,
  method = "Qlearning",
  treatment = "a",
  outcome = "y",
  prior_mean = NULL,
  prior_sd = NULL,
  sample_sd = NULL,
  default_var = 1e+06,
  latent_dim = 2,
  intermediate_dim = 32,
  epochs = 10
)
}
\arguments{
\item{data}{A data.frame including covariates, treatment, and outcome.}

\item{formula}{A formula specifying the model.}

\item{method}{Method used: "Qlearning", "Lasso", "ElasticNet", or "BayesianQ".}

\item{treatment}{Treatment column name (default "a").}

\item{outcome}{Outcome column name (default "y").}

\item{prior_mean}{Prior means (BayesianQ only).}

\item{prior_sd}{Prior variances (BayesianQ only).}

\item{sample_sd}{Sample variances (optional).}

\item{default_var}{Default variance for weak priors.}
}
\value{
A list containing model, methodvalue, recommended treatments, and more.
}
\description{
Supports standard Q-learning, Lasso, Elastic Net, and Bayesian Weighted Q-learning.
}
